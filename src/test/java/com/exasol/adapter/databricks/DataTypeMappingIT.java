package com.exasol.adapter.databricks;

import static com.exasol.matcher.ResultSetStructureMatcher.table;
import static org.hamcrest.Matchers.equalTo;
import static org.hamcrest.Matchers.startsWith;

import java.math.BigDecimal;
import java.util.stream.Stream;

import org.junit.jupiter.api.*;
import org.junit.jupiter.params.ParameterizedTest;
import org.junit.jupiter.params.provider.CsvSource;
import org.junitpioneer.jupiter.DefaultTimeZone;

import com.exasol.adapter.databricks.databricksfixture.DatabricksSchema;
import com.exasol.adapter.databricks.fixture.exasol.ExasolVirtualSchema;
import com.exasol.dbbuilder.dialects.Table;

@DefaultTimeZone("UTC")
class DataTypeMappingIT extends AbstractIntegrationTestBase {

    // Inserting values into a generated column fails, so we need to run this separately from tests that insert rows.
    @TestFactory
    Stream<DynamicNode> dataTypeGeneratedColumn() {
        return testSetup.datatypeTest() //
                .addValueTest("string generated always as ('gen')").expectVarchar().done().buildTests();
    }

    @TestFactory
    @SuppressWarnings("java:S5961") // More than 25 assertions are OK because we use dynamic tests
    Stream<DynamicNode> dataTypeMapping() {
        // https://docs.databricks.com/en/sql/language-manual/sql-ref-datatypes.html
        final String longestExasolCharValue = "a".repeat(2000);
        return testSetup.datatypeTest() //
                .addValueTest("CHAR(5)").expectType("CHAR(5) UTF8", 5L).nullValue().value("abc", "abc  ").value("12345")
                .value("öäüß ").done()

                .addValueTest("CHAR(3000000)").nullValue().value(longestExasolCharValue).done() //

                .addValueTest("VARCHAR(10)").expectType("VARCHAR(10) UTF8", 10L).nullValue().value("abc")
                .value("1234567890").value("öäüß").done()

                .addValueTest("VARCHAR(3000000)").expectVarchar().nullValue().value("abc").done()

                .addValueTest("string").expectVarchar().nullValue().value("abc").value("1234567890").value("öäüß")
                .done()

                .addValueTest("string not null").expectVarchar().value("not null").value("abc").value("1234567890")
                .value("öäüß").value("not null").value("not null").value("not null").value("not null").value("not null")
                .done()

                .addValueTest("string comment 'my column'").expectVarchar().nullValue().value("abc").value("1234567890")
                .value("öäüß").done()

                .addValueTest("TINYINT").expectDecimal(3, 0).nullValue().value((short) -128).value((short) 0)
                .value((short) 127).done()

                .addValueTest("SMALLINT").expectDecimal(5, 0).nullValue().value(-32768).value(0).value(32767).done()

                .addValueTest("INT").expectDecimal(10, 0).nullValue().value(-2_147_483_648L).value(0L)
                .value(2_147_483_647L).done()

                .addValueTest("BIGINT").expectDecimal(19, 0).nullValue().value(new BigDecimal("-9223372036854775808"))
                .value(BigDecimal.valueOf(0)).value(new BigDecimal("9223372036854775807")).done()

                .addValueTest("BIGINT generated by default as identity").expectDecimal(19, 0).nullValue()
                .value(new BigDecimal("-9223372036854775808")).value(BigDecimal.valueOf(0))
                .value(new BigDecimal("9223372036854775807")).done()

                .addValueTest("DECIMAL(1,0)").expectDecimal(1, 0).nullValue().value((short) -9).value((short) 0)
                .value((short) 9).done().addValueTest("decimal(1,1)").expectDecimal(1, 1).nullValue()
                .value(new BigDecimal("-0.9")).value(0, new BigDecimal("0.0")).value(new BigDecimal("0.9")).done()

                .addValueTest("DECIMAL(4,2)").expectDecimal(4, 2).nullValue().value(new BigDecimal("-99.99"))
                .value(0, new BigDecimal("0.00")).value(new BigDecimal("99.99")).done()

                .addValueTest("DECIMAL(10)").expectDecimal(10, 0).nullValue().value(-9999999999L).value(0L)
                .value(9999999999L).done()

                .addValueTest("DECIMAL(36)").expectDecimal(36, 0).nullValue()
                .value(new BigDecimal("-9223372036854775808")).value(BigDecimal.valueOf(0))
                .value(new BigDecimal("9223372036854775807")).done()

                .addValueTest("DECIMAL(36,36)").expectDecimal(36, 36).nullValue().value(0, new BigDecimal("0E-36"))
                .done()

                .addValueTest("FLOAT").expectType("DOUBLE", 64).nullValue().value(0D)
                .value(-3.402E+38, -3.4020000005553803E38).value(-1.175E-37, -1.1749999727240737E-37)
                .value(+1.175E-37, +1.1749999727240737E-37).value(+3.402E+38, +3.4020000005553803E38).done()

                // reduced precision
                .addValueTest("DOUBLE").expectType("DOUBLE", 64).nullValue().value(-1.7976E+308).value(-2.225E-307)
                .value(+2.225E-307).value(+1.7976E+308).value(0, 0.0).done()

                // Inserting true/false into databricks fails, so we insert 1/0
                .addValueTest("BOOLEAN").expectType("BOOLEAN", 1).nullValue().value(1, true).value(0, false).done() //

                .addValueTest("DATE").expectType("DATE", 10).nullValue().date("2021-7-1", "2021-07-01").done()

                .addValueTest("TIMESTAMP").expectType("TIMESTAMP(3)", 29).nullValue()
                .timestamp("2021-7-1T8:43:28UTC+3" /* = 2021-07-01T05:43:28.000+00:00 */, "2021-7-1 05:43:28").done()

                .addValueTest("TIMESTAMP_NTZ").expectType("TIMESTAMP(3)", 29).nullValue()
                .timestamp("2021-7-1T8:43:28", "2021-7-1 08:43:28").done()

                .addValueTest("INTERVAL YEAR").expectIntervalYearToMonth().nullValue().value("+100", "+000000100-00")
                .value("-5", "-000000005-00").done()

                .addValueTest("INTERVAL YEAR TO MONTH").expectIntervalYearToMonth().nullValue()
                .value("-100-10", "-000000100-10").done()

                .addValueTest("INTERVAL MONTH").expectIntervalYearToMonth().nullValue().value("-3600", "-000000300-00")
                .done()

                .addValueTest("INTERVAL DAY").expectIntervalDayToSecond().nullValue()
                .value("10", "+000000010 00:00:00.000000000").done() //
                .addValueTest("INTERVAL DAY TO HOUR").expectIntervalDayToSecond().nullValue()
                .value("10 23", "+000000010 23:00:00.000000000").done() //
                .addValueTest("INTERVAL DAY TO MINUTE").expectIntervalDayToSecond().nullValue()
                .value("10 23:59", "+000000010 23:59:00.000000000").done() //
                .addValueTest("INTERVAL DAY TO SECOND").expectIntervalDayToSecond()
                .value("11 23:4:0", "+000000011 23:04:00.000000000").done() //
                .addValueTest("INTERVAL HOUR").expectIntervalDayToSecond().nullValue()
                .value("23", "+000000000 23:00:00.000000000").done() //
                .addValueTest("INTERVAL HOUR TO MINUTE").expectIntervalDayToSecond().nullValue()
                .value("23:59", "+000000000 23:59:00.000000000").done() //
                .addValueTest("INTERVAL HOUR TO SECOND").expectIntervalDayToSecond().nullValue()
                .value("23:59:59", "+000000000 23:59:59.000000000")
                .value("200:13:50.3", "+000000008 08:13:50.300000000").done() //
                .addValueTest("INTERVAL MINUTE").expectIntervalDayToSecond().nullValue()
                .value("59", "+000000000 00:59:00.000000000").done() //
                .addValueTest("INTERVAL MINUTE TO SECOND").expectIntervalDayToSecond().nullValue()
                .value("59:59", "+000000000 00:59:59.000000000").value("0:0.1", "+000000000 00:00:00.100000000").done() //
                .addValueTest("INTERVAL SECOND").expectIntervalDayToSecond().nullValue()
                .value("59", "+000000000 00:00:59.000000000").value("0.0001", "+000000000 00:00:00.000000000").done()

                // Generic VARCHAR mapping for unsupported data types
                // Inserting non-null values requires custom SQL statements, see unsupportedDataTypesMappedToVarchar()
                .addValueTest("ARRAY<INT>").expectVarchar().nullValue().done() //
                .addValueTest("MAP<INT,STRING>").expectVarchar().nullValue().done() //
                .addValueTest("STRUCT<id:INT,name:STRING>").expectVarchar().nullValue().done() //
                .addValueTest("VARIANT").expectVarchar().nullValue().done() //

                .buildTests();
    }

    @Test
    void readingTooLongCharFails() {
        final DatabricksSchema databricksSchema = testSetup.databricks().createSchema();
        final String tooLongExasolCharValue = "a".repeat(2001);
        final Table table = databricksSchema.createTable("tab", "col", "char(3000)").insert(tooLongExasolCharValue);
        final ExasolVirtualSchema vs = testSetup.exasol().createVirtualSchema(databricksSchema);
        testSetup.exasol().assertions().assertQueryFails("select * from " + vs.qualifyTableName(table), startsWith(
                "ETL-3003: [Column=0 Row=0] [String data right truncation. String length exceeds limit of 2000 characters]"));
    }

    @ParameterizedTest
    @CsvSource(delimiterString = ";", value = { //
            "ARRAY<TINYINT>; CAST(ARRAY(1, 2, 3) AS ARRAY<TINYINT>); [1,2,3]",
            "MAP<STRING,INT>; map('red', 1, 'green', 2); {\"green\":2,\"red\":1}",
            "STRUCT<id:INT,name:STRING>; named_struct('id', 5, 'name', 'Spark'); {\"id\":5,\"name\":\"Spark\"}",
            "VARIANT; parse_json('{\"key\": 123, \"data\": [4, 5, \"str\"]}'); {\"data\":[4,5,\"str\"],\"key\":123}" })
    void unsupportedDataTypesMappedToVarchar(final String databricksType, final String insertSql,
            final String expectedValue) {
        final DatabricksSchema databricksSchema = testSetup.databricks().createSchema();
        final Table tab = databricksSchema.createTable("tab", "col", databricksType);
        testSetup.databricks()
                .executeStatement("INSERT INTO %s VALUES (%s)".formatted(tab.getFullyQualifiedName(), insertSql));
        final ExasolVirtualSchema vs = testSetup.exasol().createVirtualSchema(databricksSchema);
        testSetup.exasol().assertions().query("select * from " + vs.qualifyTableName(tab),
                table("VARCHAR").row(expectedValue).matches());
    }

    @ParameterizedTest
    @CsvSource(delimiterString = ";", value = { "BINARY; BINARY" })
    void unsupportedDataTypes(final String databricksType, final String typeInErrorMessage) {
        final DatabricksSchema databricksSchema = testSetup.databricks().createSchema();
        databricksSchema.createTable("tab", "col", databricksType + " COMMENT 'my column'");
        testSetup.exasol().assertions().assertVirtualSchemaFails(databricksSchema,
                equalTo(String.format(
                        """
                                E-VSDAB-8: Exasol does not support Databricks data type '%s' of column 'col' at position 0 with comment 'my column'

                                Mitigations:

                                * Please remove the column or change the data type.""",
                        typeInErrorMessage)));
    }

    @Test
    void unsupportedDecimalPrecision() {
        final DatabricksSchema databricksSchema = testSetup.databricks().createSchema();
        databricksSchema.createTable("tab", "col", "DECIMAL(38) COMMENT 'my column'");
        testSetup.exasol().assertions().assertVirtualSchemaFails(databricksSchema,
                equalTo("""
                        E-VSDAB-11: Unsupported decimal precision 'decimal(38,0)' for column 'col' at position 0 (comment: 'my column'), Exasol supports a maximum precision of 36.

                        Mitigations:

                        * Please remove the column or change the data type."""));
    }
}
