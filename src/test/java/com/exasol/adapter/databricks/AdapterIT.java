package com.exasol.adapter.databricks;

import static org.hamcrest.Matchers.*;

import org.junit.jupiter.api.Test;
import org.junit.jupiter.params.ParameterizedTest;
import org.junit.jupiter.params.provider.CsvSource;

import com.exasol.adapter.databricks.databricksfixture.DatabricksSchema;
import com.exasol.dbbuilder.dialects.exasol.VirtualSchema;

class AdapterIT extends AbstractIntegrationTestBase {

    @Test
    void createFailsForMissingArguments() {
        assertCreateVirtualSchemaFails(null, null, containsString("F-VSDAB-1: Property 'CATALOG_NAME' is missing"));
    }

    @Test
    void createFailsForNonExistingDatabricksCatalog() {
        assertCreateVirtualSchemaFails("no-such-catalog", "schema",
                allOf(containsString("E-VSDAB-5: HTTP request for URL 'https://"),
                        containsString("Catalog 'no-such-catalog' does not exist")));
    }

    @Test
    void createFailsForNonExistingDatabricksSchema() {
        assertCreateVirtualSchemaFails("system", "no-such-schema",
                allOf(containsString("E-VSDAB-5: HTTP request for URL 'https://"),
                        containsString("Schema 'system.no-such-schema' does not exist.")));

    }

    @Test
    void schemaMetadataAvailable() {
        final VirtualSchema vs = testSetup.exasol().createVirtualSchema("system", "information_schema");
        testSetup.exasol().assertions().virtualSchemaExists(vs);
    }

    @Test
    void dataTypeMapping() {
        // https://docs.databricks.com/en/sql/language-manual/sql-ref-datatypes.html
        testSetup.datatypeMappingTest() //
                .add("string", "VARCHAR(2000000) UTF8", 2000000L)
                .add("string not null", "VARCHAR(2000000) UTF8", 2000000L)
                .add("string generated always as ('gen')", "VARCHAR(2000000) UTF8", 2000000L)
                .add("string comment 'my column'", "VARCHAR(2000000) UTF8", 2000000L) //
                .add("TINYINT", "DECIMAL(19)", 0) //
                .add("SMALLINT", "DECIMAL(19)", 0) //
                .add("INT", "DECIMAL(19)", 0) //
                .add("BIGINT", "DECIMAL(19)", 0) //
                .add("BIGINT generated by default as identity", "VARCHAR(2000000) UTF8", 2000000L) //
                .add("FLOAT", "DECIMAL(19)", 0) //
                .add("DOUBLE", "DECIMAL(19)", 0) //
                .add("DECIMAL", "DECIMAL(10)", 0) //
                .add("DECIMAL(1,0)", "DECIMAL(1)", 0) //
                .add("DECIMAL(1,1)", "DECIMAL(1,1)", 0) //
                .add("DECIMAL(38)", "DECIMAL(38)", 0) //
                .add("DECIMAL(38,38)", "DECIMAL(38,38)", 0) //

                .add("BINARY", "VARCHAR", 0) //
                .add("BOOLEAN", "BOOLEAN", 0) //
                .add("TIMESTAMP", "TIMESTAMP", 0) //
                .add("TIMESTAMP_NTZ", "TIMESTAMP WITH LOCAL TIME ZONE", 0) //
                .add("INTERVAL YEAR TO MONTH", "INTERVAL", 0) //
                .add("INTERVAL HOUR TO SECOND", "INTERVAL", 0) //
                .verify();
    }

    @ParameterizedTest
    @CsvSource(delimiterString = ";", value = { "ARRAY<INT>; ARRAY", "MAP<INT,STRING>; MAP",
            "STRUCT<id:INT,name:STRING>; STRUCT", "VARIANT; VARIANT" })
    void unsupportedDataTypes(final String databricksType, final String typeInErrorMessage) {
        final DatabricksSchema databricksSchema = testSetup.databricks().createSchema();
        databricksSchema.createTable("tab", "col", databricksType + " COMMENT 'my column'");
        testSetup.exasol().assertions().assertVirtualSchemaFails(databricksSchema,
                equalTo(String.format(
                        """
                                E-VSDAB-8: Exasol does not support Databricks data type '%s' of column 'col' at position 0 with comment 'my column'

                                Mitigations:

                                * Please remove the column or change the data type.""",
                        typeInErrorMessage)));
    }
}
